
---
layout: post
title:  "Spark1.6内存管理(二) 实例讲解：Spark管理页面中Storage Memory是如何计算的？"
categories: Spark
tags:  Spark
author: wisgood
---


书接上文： https://blog.csdn.net/wisgood/article/details/78069753
本文主要讲解879.0MB是如何算出来的？spark用的是1.6版本。
![这里写图片描述](https://img-blog.csdn.net/20180408124708938?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dpc2dvb2Q=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
对应程序的参数设置为 

```
spark-shell  --executor-memory 1536M  
```

# Storage Memory

该页面显示的Storage Memory 实际是上文中介绍的 Storage Memory 和 Execution Memory的和,是由Spark管理的内存池总和。
即
```java
Storage Memory =(executorMemory-300m)*0.75
```

根据上面公式，计算出来的Storage Memory=927M```(1536-300)*0.75```,比显示的879大很多。为什么？
```java
其实程序在计算的时候，用的Storage Memory是通过Runtime.getRuntime.maxMemory拿到的,Runtime.getRuntime.maxMemory是程序能够使用的最大内存，会比executorMemory值小。原因是java新生代中，有2个Survivor，而只有1个是可用的，所以Runtime.getRuntime.maxMemory实际=Eden+Survivor+Old Gen，比设置的内存要小。
```

为了准确计算```Runtime.getRuntime.maxMemory```这个值，我们在spark启动的时候，添加一些其他参数,
```java 
--conf "spark.executor.extraJavaOptions=-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintHeapAtGC"
``` 
启动命令变成
```java
spark-shell  --executor-memory 1536M --conf "spark.executor.extraJavaOptions=-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintHeapAtGC" 
```

这样做的目的是在每个executor执行过程中，打印部分gc log。通过这个，我们能比较清楚的知道executor内存中新生代 老年代情况。如下图
![这里写图片描述](https://img-blog.csdn.net/20180408130312454?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dpc2dvb2Q=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

据此我们可以计算Runtime.getRuntime.maxMemory
```java

Runtime.getRuntime.maxMemory=393216 K+65536 K+1048576 K=1472 M

```
此时再计算hadoop页面中显示的Storage Memory
```
Storage Memory = 879 M = (1472-300)*0.75
```