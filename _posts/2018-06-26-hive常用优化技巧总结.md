---
layout: post
title:  "hive常用优化技巧总结"
categories: Hive
tags:  Hive
author: wisgood
---

* content
{:toc} 

# 1、优化思路

## 1.1、确定优化目标

优化的目标是啥？
- 时间？
- 存储？
- 整个集群负载?

## 1.2、分析瓶颈

借助hadoop执行时的页面：
- 看作业时间，有无长尾作业 
- 借助各种counter
- 借助于各种日志
- debug

## 1.3、确定优化方案并迭代

# 2、优化：目标是减少作业执行时间

## 2.1、优化map任务

### 2.1.1 map数太多
- 1）使用CombineHiveInputFormat合并小文件
```
set mapred.max.split.size=100000000;
set mapred.min.split.size.per.node=100000000;
set mapred.min.split.size.per.rack=100000000;
set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
```

- 2）通过调整TextFileInputFormat的参数
```java
mapreduce.input.fileinputformat.split.minsize
mapreduce.input.fileinputformat.split.maxsize
```

blockSize
详情参考博客：https://blog.csdn.net/wisgood/article/details/79178663 
### 2.1.2 map数太少
- 1）通过调整TextFileInputFormat的参数
同上。
- 2）确定数据源是可以Splitable。
如果是lzo，需加添加index；gz不支持split；

### 2.1.3 减少map的输入数据

- 1）分区裁剪，分区条件不成立
- 2）使用列存储

### 2.1.4 减少map的输出数据

- 1）列裁剪
只输出需要的数据
- 2）压缩
使用hive参数指定map输出结果压缩
```java
set hive.exec.compress.intermediate=true;
set hive.intermediate.compression.codec=org.apache.hadoop.io.compress.SnappyCodec
```

使用mr参数指定map输出结果压缩
```
set mapred.compress.map.output=true;
set mapred.map.output.compression.codec=org.apache.hadoop.io.compress.LzoCodec
```
- 3）map端combine

### 2.1.5 map内存优化

通过参数优化
```
set mapreduce.map.memory.mb=3072 ;
set mapreduce.map.java.opts=-Xmx2048M  -XX:MaxPermSize=128m ;
```

### 2.1.6 map过程中参数优化
待补充
## 2.2、优化reduce任务

### 2.2.1 调整reduce个数 

- 1）调整hive.exec.reducers.bytes.per.reducer参数的值
```set hive.exec.reducers.bytes.per.reducer=500000000;```

- 2）调整mapred.reduce.tasks 
```set mapred.reduce.tasks = 15;```

### 2.2.2 调整reduce内存 
```java
set mapreduce.reduce.memory.mb=5120 ;
set mapreduce.reduce.java.opts=-Xmx5000M  -XX:MaxPermSize=128m ;
```
### 2.2.3 调整reduce参数 
待补充
##2.3、任务级别优化

### 2.3.1 让作业并行

```java
//设置hive任务并行度
set hive.exec.parallel=true;
set hive.exec.parallel.thread.number=10;
```

### 2.3.2 作业优先级
- 1）静态调整
通过调整任务指定的队列或者任务优先级
```
SET mapreduce.job.queuename root.temp_fast;
SET mapreduce.job.priority VERY_HIGH;
```

- 2）	动态调整
hadoop1.0及以下版本：
```java
hadoop job -set-priority job_201707060942_6121418 VERY_HIGH 
```

hadoop2.0及以上版本：
```java
yarn application -appId application -updatePriority VERY_HIGH  //调整优先级
yarn application  -movetoqueue  application_1478676388082_963529  -queue  root.etl //调整队列
```

### 2.3.3 任务推测执行	
```
mapreduce.map.speculative
mapreduce.reduce.speculative 
```

### 2.3.4 使用本地模式
参考链接：https://blog.csdn.net/wisgood/article/details/17383247 
```java
set hive.exec.mode.local.auto=true; 
set hive.exec.mode.local.auto.inputbytes.max=50000000;
set hive.exec.mode.local.auto.tasks.max=10;
```

## 2.4、join优化

### 2.4.1 mapjoin 

- 1）手动设置 
/*+MapJOIN (tbl)*/
- 2）自动设置
```java
set hive.auto.convert.join=true;
set hive.mapjoin.smalltable.filesize;默认25000000L
```

参考博客：https://blog.csdn.net/wisgood/article/details/80066475 

### 2.4.2 bucket join

```java
set hive.optimize.bucketMapjoin = true;
```

或者
```java
set Hive.optimize.bucketMapjoin.Sortedmerge = true;
set Hive.input.format = org.apache.Hadoop.Hive.ql.io.BucketizedHiveInputFormat;
```

### 2.4.3 大key引起的倾斜


- 1）针对大key做特殊处理
过滤掉无效的大key 或者 将大key单独做join然后union
- 2）参数优化
```java
set hive.skewjoin.key=100000; 
set hive.optimize.skewjoin=true;
```

### 2.4.4 用group实现join


### 2.4.5 表连接顺序优化

通过给出一些Hint信息来启发JOIN操作，这指定了将哪个表作为大表，从而得到优化。例如. a表被视为大表，则首先会对表b和c进行JOIN，然后再将得到的结果与表a进行JOIN
```sql
SELECT /*+ STREAMTABLE(a) */ a.val, b.val, c.val
FROM a JOIN b ON (a.key = b.key1) JOIN c ON (c.key = b.key1)

```

### 2.4.6 where条件优化

左连接时，左表中出现的JOIN字段都保留，右表没有连接上的都为空。对于带WHERE条件的JOIN语句，例如：
SELECT a.val, b.val FROM a LEFT OUTER JOIN b ON (a.key=b.key)
WHERE a.ds='2009-07-07' AND b.ds='2009-07-07'
执行顺序是，首先完成2表JOIN，然后再通过WHERE条件进行过滤，这样在JOIN过程中可能会输出大量结果，再对这些结果进行过滤，比较耗时。可以进行优化，将WHERE条件放在ON后，例如：
SELECT a.val, b.val FROM a LEFT OUTER JOIN b
ON (a.key=b.key AND b.ds='2009-07-07' AND a.ds='2009-07-07')
这样，在JOIN的过程中，就对不满足条件的记录进行了预先过滤，可能会有更好的表现。

## 2.5 group优化

### 2.5.1 map端聚合

```sql
set hive.map.aggr=true;
```

### 2.5.2 额外增加job

```sql
hive.groupby.skewindata 
```

## 2.6 distinct优化 

### 2.6.1 通过group实现distinct 

Group可以通过增加reduce数目提高速度。
https://blog.csdn.net/wisgood/article/details/18040363 
## 2.7 非常规思路

### 2.7.1 使用更高的hive版本

### 2.7.2 使用更高效的执行引擎

如Tez,Spark
### 2.7.3 空间换时间

### 2.7.4 业务角度优化

# 3、优化：目标是减少作业后的存储

## 3.1. 降低存储大小

### 3.1.1 使用压缩
```sql
set hive.exec.compress.output=true;
set mapred.output.compression.codec=org.apache.hadoop.io.compress.GzipCodec;
```

## 3.2 减少文件数目

### 3.2.1 合并文件

- hive.merge.mapfiles 在map-only job后合并文件，默认true
- hive.merge.mapredfiles 在map-reduce job后合并文件，默认false
上述选项默认为true，当为true时，会额外启动1个job将输出压缩。

hive.merge.smallfiles.avgsize 平均文件大小，是决定是否执行合并操作的阈值，默认16000000
当job生成的平均文件大小小于该值时，才会额外启动一个job压缩，否则不启动。该参数生效的前提是hive.merge.mapfiles和hive.merge.mapredfiles其中一个为true。
- 1）	当hive.merge.mapfiles为tue时，适用于只有map的作业
- 2）	当hive.merge.mapredfiles为true时，适用于有reduce的作业

hive.merge.size.per.task 合并后每个文件的大小，默认256000000，实际最后生成文件的值为max(hive.merge.size.per.task, hive.merge.smallfiles.avgsize)
### 3.2.2归档

```sql
set hive.archive.enabled= true;
set hive.archive.har.parentdir.settable= true;
set har.partfile.size=1099511627776;
ALTER TABLE srcpart ARCHIVE PARTITION(ds= '2008-04-08', hr= '12' );
ALTER TABLE srcpart UNARCHIVE PARTITION(ds= '2008-04-08', hr= '12' );		
```
### 3.2.3 使用CombineInputFormat

